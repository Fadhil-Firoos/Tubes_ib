{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WD9WVmr9R1G"
      },
      "source": [
        "TUGAS BESAR INTELEGENSI BUATAN - RB\n",
        "\n",
        "NAMA KELOMPOK :\n",
        "1. Bayu Agaluh Wijaya        121140097\n",
        "2. Fadhil Firoos             121140142\n",
        "3. Ilham Yoga Pratama        121140081\n",
        "4. Andrean Syahrezi          121140169\n",
        "5. Maharani Triza Putri      121140071"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm7QkmvOdxdV"
      },
      "outputs": [],
      "source": [
        "# import library\n",
        "import string\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from util import JSONParser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtjAHN1heUl8"
      },
      "source": [
        "### Load Data\n",
        "\n",
        "Data yang digunakan merupakan data JSON. Tujuannya adalah mengubah bentuk JSON menjadi dalam bentuk tabel agar mudah ditraining menggunakan *scikit-learn*.\n",
        "Kami sudah membuat parser khusus untuk data dengan format tersebut didalam direktori `util/` yang bernama `JSONParser`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TUAECALee4o",
        "outputId": "f2dd7367-4b9c-4f72-8d94-eee58538d154"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "path = \"data/intents.json\"\n",
        "\n",
        "# buat objek JSONParser dan parse data intents.json\n",
        "jp = JSONParser()\n",
        "jp.parse(path)\n",
        "\n",
        "# simpan dataframe dalam variabel df\n",
        "df = jp.get_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sbkL2oL9eju7",
        "outputId": "9b1844c8-5912-44f8-f049-9d15a4bf7dbf"
      },
      "outputs": [],
      "source": [
        "# lihat 5 data pertama\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66G7vsegels6",
        "outputId": "927d4a57-783c-438d-b285-01e704a38f38"
      },
      "outputs": [],
      "source": [
        "# hitung jumlah data per tag / inten\n",
        "df.intents.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT7kCYKTeorp"
      },
      "source": [
        "### Praproses Data\n",
        "\n",
        "Pada bagian ini data training akan dibersihkan dan dilakukan praproses apabila diperlukan.\n",
        "\n",
        "Praproses yang dilakukan adalah :\n",
        "- Case Folding : Mengubah semua alfabet menjadi huruf kecil\n",
        "- Menghapus tanda baca\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPZvULokeqE4"
      },
      "outputs": [],
      "source": [
        "def preprocess(chat):\n",
        "    \"\"\"\n",
        "    Fungsi yang digunakan untuk melakukan praproses\n",
        "    \"\"\"\n",
        "    # konversi ke lowercase\n",
        "    chat = chat.lower()\n",
        "    # menghapus tanda baca\n",
        "    tandabaca = tuple(string.punctuation)\n",
        "    chat = ''.join(ch for ch in chat if ch not in tandabaca)\n",
        "    return chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDxUJOXletBf"
      },
      "outputs": [],
      "source": [
        "# implementasikan fungsi preprocess ke string\n",
        "df['text_input_prep'] = df.text_input.apply(preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIKgfDGqe66g"
      },
      "source": [
        "Apabila kita lihat hasilnya maka kita dapati hal berikut :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lq2h4Y4Deu0U",
        "outputId": "943e7129-6b5a-4d04-897c-a2eb39019de4"
      },
      "outputs": [],
      "source": [
        "df[['text_input', 'text_input_prep']].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYusyCC7e1JN"
      },
      "source": [
        "Kita dapat lihat bahwa kolom kiri merupakan kolom data sebelum di praproses sedangkan yang kanan adalah input yang sudah di praproses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-KJ4NTLezXV"
      },
      "source": [
        "### Vektorisasi\n",
        "\n",
        "Sebelum kita masukkan data kita kedalam algoritma machine learning, kita perlu melakukan vektorisasi terlebih dahulu. Karena input yang diterima oleh model machine learning harus berupa matriks sedangkan dataset yang kita proses berupa teks.\n",
        "\n",
        "Metode vektorisasi paling sederhana adalah metode *bag of words* yaitu metode pengumpulan *vocab* yang terdapat pada *corpus*.\n",
        "Metode *bag of words* yang paling sederhana adalah metode `CountVectorizer` yang terdapat pada *scikit-learn*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_Cq07RFfTKy"
      },
      "outputs": [],
      "source": [
        "# inisiasi objek CountVectorizer\n",
        "vect = CountVectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCLPf_wKfU1y"
      },
      "source": [
        "Langkah penting dalam metode *bag of words* adalah mengumpulkan *vocab* yang terdapat pada *corpus* yang kita miliki. Dalam scikit-learn kita dapat lakukan dengan cara :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "ZlfGPtsifXI8",
        "outputId": "dc2fa238-85ad-4141-c30d-76fb9d261b28"
      },
      "outputs": [],
      "source": [
        "# mengumpulkan vocab dari data teks yang sudah dilakukan praproses\n",
        "vect.fit(df['text_input_prep'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx2H89lQfY-6",
        "outputId": "a7a89733-e0af-402b-cc33-cf7c8de2b941"
      },
      "outputs": [],
      "source": [
        "# Lihat list vocab\n",
        "feature_names = vect.get_feature_names_out()[:10]  # batasi hanya 10 vocab teratas\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPpMFWtgfa4a"
      },
      "source": [
        "Selanjutnya konversi data teks menjadi matriks sesuai vocab yang sudah dibuat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHhR7tN5fc-n",
        "outputId": "6f84f49f-7c7e-4596-f634-06ad54074543"
      },
      "outputs": [],
      "source": [
        "# ubah data teks menjadi matriks\n",
        "text_vect = vect.transform(df.text_input_prep)\n",
        "\n",
        "text_vect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB3l_zBBfgph"
      },
      "source": [
        "Kita bisa lihat bahwa data teks kita sudah berubah menjadi bentuk *sparse matrix*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxr95gyufiTh",
        "outputId": "4e052366-023d-4086-d0bc-121b5e3b7ae0"
      },
      "outputs": [],
      "source": [
        "# Lihat list vocab\n",
        "feature_names = vect.get_feature_names_out()[:10]  # batasi hanya 10 vocab teratas\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgSK9XaBfkvc"
      },
      "source": [
        "Jika kita menggunakan dengan data yang besar, kita tidak disarankan melihat representasi matriks datanya karena akan membuat komputer menjadi berat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_i-bebSfm_B"
      },
      "source": [
        "### Modelling\n",
        "\n",
        "Setelah data siap, saatnya ditrain kedalam algoritma machine learning.\n",
        "Dalam kasus ini kita menggunakan Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "4m33xf1nfonJ",
        "outputId": "526963a4-9c9b-41d9-cbfb-2ddf398afc1a"
      },
      "outputs": [],
      "source": [
        "# deklarasi objek MultinomialNB\n",
        "nb = MultinomialNB()\n",
        "\n",
        "# training data, dengan X : text_vect dan y : intents\n",
        "nb.fit(text_vect, df.intents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqDCTGMsfqi3"
      },
      "source": [
        "Setelah model dilatih kita coba keluarkan hasil prediksi dari suatu input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGMf1CWdfsEy",
        "outputId": "c929fc76-5f6f-4b01-f825-1cccdb447765"
      },
      "outputs": [],
      "source": [
        "# input string dari user\n",
        "chat = input(\"Masukkan String : \")\n",
        "\n",
        "# lakukan preproses\n",
        "chat = preprocess(chat)\n",
        "\n",
        "# ubah teks menjadi vektor\n",
        "chat = vect.transform([chat])\n",
        "\n",
        "# prediksi vektor teks kedalam model machine learning\n",
        "res = nb.predict(chat)\n",
        "\n",
        "# tampilkan hasil prediksi\n",
        "print(f\"Hasil prediksi : {res[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA4SajT3fuvm"
      },
      "source": [
        "Supaya hasil menjadi lebih natural, kita lakukan prediksi dengan probabilitas sehingga apabila hasil prediksi kurang dari threshold probabilitas yang ditentukan, kita bisa buat bot untuk bilang \"tidak mengerti\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHF9XD0nfwts",
        "outputId": "c8e2ff95-58c3-4fdc-8244-daad235b9c33"
      },
      "outputs": [],
      "source": [
        "# input string dari user\n",
        "chat = input(\"Masukkan String : \")\n",
        "\n",
        "# lakukan preproses\n",
        "chat = preprocess(chat)\n",
        "\n",
        "# ubah teks menjadi vektor\n",
        "chat = vect.transform([chat])\n",
        "\n",
        "# prediksi vektor teks kedalam model machine learning\n",
        "res = nb.predict_proba(chat)\n",
        "\n",
        "# ambil nilai probabilitas tertinggi\n",
        "max_prob = max(res[0])\n",
        "max_idx = np.argmax(res[0])\n",
        "print(f\"Max Prob : {max_prob}\\nMax Index: {max_idx}\\nLabel: {nb.classes_[max_idx]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtlziQtYfzxc"
      },
      "source": [
        "### Efisiensi dengan Pipeline\n",
        "\n",
        "Dari proses diatas kita bisa lihat apabila ada data teks maka kita perlu proses dalam dua langkah, yaitu vektorisasi dan pemodelan. Supaya proses menjadi lebih ringkas dan lebih mudah dalam proses deployment, kita akan buat pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "q6FmiRNPf1M0",
        "outputId": "3db42feb-9bb4-4b7c-a983-1ba2ad356484"
      },
      "outputs": [],
      "source": [
        "# Deklarasi pipeline yang mengandung vektorisasi (CountVectorizer) & pemodelan (MultinomialNB)\n",
        "pipe = make_pipeline(CountVectorizer(),\n",
        "                     MultinomialNB())\n",
        "\n",
        "# Training\n",
        "pipe.fit(df.text_input, df.intents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-YLHSz0f3N4"
      },
      "source": [
        "Dapat kita lihat dari proses training diatas, seolah-olah kita langsung memasukkan data teks dan labelnya langsung kedalam \"*black box*\" sehingga proses prediksi akan lebih ringkas.\n",
        "\n",
        "Untuk inference dengan pipeline dapat kita lakukan dengan cara berikut :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C90ihZOYf4hB",
        "outputId": "1a1a9501-3379-4737-bb70-42ef54b23d5c"
      },
      "outputs": [],
      "source": [
        "# input string dari user\n",
        "chat = input(\"Masukkan String : \")\n",
        "\n",
        "# lakukan preproses\n",
        "chat = preprocess(chat)\n",
        "\n",
        "# prediksi teks kedalam pipeline\n",
        "res = pipe.predict_proba([chat])\n",
        "\n",
        "# ambil nilai probabilitas tertinggi\n",
        "max_prob = max(res[0])\n",
        "max_idx = np.argmax(res[0])\n",
        "print(f\"Max Prob : {max_prob}\\nMax Index: {max_idx}\\nLabel: {nb.classes_[max_idx]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtPta8l4f6i2"
      },
      "source": [
        "Dapat kita lihat bahwa teks baru setelah praproses bisa langsung masuk kedalam pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TRodrwof9QQ"
      },
      "source": [
        "### Simulasi Inference\n",
        "\n",
        "Selanjutnya kita akan simulasikan chatbot mulai dari mendapatkan input sampai ke respon\n",
        "\n",
        "Dalam kasus ini apabila intent yang terdeteksi adalah `bye` maka program berhenti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLfmIf4XgAo4",
        "outputId": "2ccfb6c8-9a37-44cd-ae9d-8d61539abca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot : Halo!\n",
            "Bot : Aku bantu Kelompok IB dari Fadhil, Bayu, Ilham, Andreyan, Maharani dalam UAS IB\n",
            "Bot : Kakak bisa tanya-tanya nama aku, apa yang aku lakukan dan yang berhubungan dengan pengenalan python\n",
            "Bot : python kaak, jangan bikin emosi deh\n",
            "Bot : python kaak, jangan bikin emosi deh\n",
            "Bot : Python adalah bahasa pemrograman tingkat tinggi yang bersifat interpretatif, mudah dibaca, dan mendukung paradigma pemrograman berorientasi objek, prosedural, serta fungsional. Dikembangkan oleh Guido van Rossum pada awal 1990-an, Python menjadi populer karena sintaksisnya yang sederhana dan ekosistemnya yang kaya. Python digunakan dalam berbagai bidang seperti pengembangan web, ilmu data, kecerdasan buatan, pengembangan perangkat lunak, dan otomatisasi tugas. Kelebihan Python termasuk keberlanjutan, portabilitas, dan komunitas pengguna yang besar, yang berkontribusi pada pertumbuhan dan keberlanjutan bahasa ini.\n",
            "Bot : Sampai jumpa lagi yaa\n"
          ]
        }
      ],
      "source": [
        "print(\"Anda Terhubung dengan chatbot Kami\")\n",
        "while True:\n",
        "    # input user\n",
        "    chat = input(\"Anda : \")\n",
        "    # praproses\n",
        "    chat = preprocess(chat)\n",
        "    # prediksi intent\n",
        "    res = pipe.predict_proba([chat])\n",
        "    # ambil nilai probabilitas & lokasinya\n",
        "    max_prob = max(res[0])\n",
        "    max_idx = np.argmax(res[0])\n",
        "    # kondisi jika probabilitas kurang dari threshold\n",
        "    if max_prob < 0.20:\n",
        "        print(\"Bot : Maaf Kak, aku ga ngerti\")\n",
        "    else:\n",
        "        print(f\"Bot : {jp.get_response(nb.classes_[max_idx])}\")\n",
        "    if nb.classes_[max_idx] == 'bye':\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrliDgTAgDI5"
      },
      "source": [
        "Setelah kita berhasil simulasikan bot nya dalam notebook ini, kita simpan modelnya agar dapat dideploy dengan mudah"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gBUmNiFigEp8"
      },
      "outputs": [],
      "source": [
        "with open(\"chatbot_pipeline.pkl\", \"wb\") as model_file:\n",
        "    pickle.dump(pipe, model_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
